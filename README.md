---
title: "Logistic Growth"
date: "2023-11-28"
output: html_document
---

# Question 1, 2, & 3
Questions 1, 2 and 3 can be found in the README.md file in the logistic_growth repository: [click here](https://github.com/Alanazammit64/logistic_growth)

# Question 4 - Brownian Motion 

Brownian motion is the random movement of suspended particles, with fast moving molecules or atoms that hit the particles being the cause of this random motion. It is a continuous time stochastic process, as it gives a randomly determined outcome. 


To complete this talk, I firstly had to install the necessary packages

```{r, echo = FALSE}

install.packages("ggplot2")
install.packages("gridExtra")

library(ggplot2)
library(gridExtra)

```


1) **Execute the code to produce the paths of two random walks. What do you observe?**

The script provided in the random_walk file produces the two plots below.

![Brownian motion plots](brownian_motion.png)

In these plots, I can observe the path taken by the randomly generated walks through time, with earlier time points shown in darker colours. Both walks contain 500 steps, but we can see a difference between the two graphs: the one of the left tends to have longer walks, and so talks up more of the grid space, in comparison to the shorter walks which cover less of the right hand grid. This demonstrates the randomness of the movement of a particle in a 2D space across time. 

2) **Investigate the term random seeds. What is a random seed and how does it work?**

In R Studio, a seed is a way to create reproducible results when creating code with random-number variables. Using a random seed as a starting point when generating random numbers is crucial to creating reproducible random sequences. By setting a random seed, one can ensure that the sequence of random numbers generated by a program is the same every time it runs, given the same initial seed. It is done using the set.seed(seed) function, where (seed) is replaced by a number. This has particular importance when generating code that must be reproducible, for example in statistical analyses, or when attempting to debug code that uses random numbers.  

3) **Edit the script to make a reproducible simulation of Brownian motion. Commit the file and push it to your forked reproducible-research homework repo**

The edited script can be found in the 'question-4-code/random_walk.R file', found [here](question-4-code/random_walk.R)


4) **Go to your commit history and click on the latest commit. Show the edit you made to the code in the comparison view (add this image to the README.md of the fork)**

![Commited changes](commit_changes.png)



# Question 5

**Import the data for double-stranded DNA (dsDNA) viruses taken from the Supplementary Materials of the original paper into Posit Cloud. How many rows and columns does the table have?**

```{r}
library(readr)
Cui_etal2014 <- read_csv("Cui_etal2014.csv")
View(Cui_etal2014)
```
The table has 33 rows and 13 columns



**What transformation can you use to fit a linear model to the data? Apply the transformation.**

To fit a linear model to the data, I applied a log transformation to virion volume and genome length, as these two properties have such wide ranges (5.24 to 2473.87kb for genome length and 321392 to 75000000nm2 for virion volume)
```{r}
Cui_etal2014$log_virion_volume <- log(Cui_etal2014$`Virion.volume..nm.nm.nm.`)
Cui_etal2014$log_genome_length <- log(Cui_etal2014$`Genome.length..kb.`)
```

**Find the exponent (α) and scaling factor (β) of the allometric law for dsDNA viruses and write the p-values from the model you obtained, are they statistically significant? Compare the values you found to those shown in Table 2 of the paper, did you find the same values?**

Viral particle volume can be predicted by their genome length using the allometric equation V = βL^α. Therefore to find the values of alpha (representing the exponent) and beta (the scaling factor), it was first necessary to apply a linear regression to the two variables, virion volume in nm3 and genome length in nucleotides. This was done using the code below. 

```{r}
linear_model <- lm(data = Cui_etal2014, log_virion_volume~log_genome_length)
summary(linear_model)
```
![Results of the linear model](virionmodel.png)


In this formula, log(V)=β+α*log(L). β is the intercept, and α is the value provided for log_genome_length. Therefore, the value of the exponent (α) is 1.5152, and that of the scaling factor (β) is 7.0748. These values are highly significant in explaining the relationship between virion volume (V) and genome length (L), denoted by a three star significance code. 

So, this linear model suggests a relationship between the log of virus length and the log of genome length: V = βL^α, where β ≈ 7.0748 and α ≈ 1.5152
- V ≈ 7.0748L^1.5152

From table 2 in the paper, the value of the exponent for dsDNA was recorded as 1.52, which is the same value to 2 significant figures as the value I found. The scaling factor in the paper was given as 1,182 for dsDNA, which, if we logarithmically backtransform our value of 7.0748 (e^7.0748) to give 1181.8071, is very similar to. 

**Write the code to reproduce the figure shown below**
```{r}
# Install and load necessary packages
install.packages(c("ggplot2", "janitor", "dplyr", "data.table"))
library(ggplot2)
library(janitor)
library(dplyr)
library(data.table)

# Cleaning the dataset to make the names easier to work with 
cuietal <- rename(Cui_etal2014, genome_length = "Genome length (kb)", virion_volume = "Virion volume (nm×nm×nm)")
View(cuietal)


# Subsetting the dataset to include only the columns we need 
cuietal_clean <- cuietal[, c("genome_length", "virion_volume")]
View(cuietal_clean)



# Log-transforming the variables genome length and virion volume so I can do a linear regression 
cuietal_clean$log_virion_volume <- log(cuietal_clean$virion_volume)
cuietal_clean$log_genome_length <- log(cuietal_clean$genome_length)
View(cuietal_clean) # checking these extra log-transformed variables have been added 


# Setting up the linear model 
linear_model <- lm(data = cuietal_clean, log_virion_volume~log_genome_length)
summary(linear_model) 
# This summary yields the same results as in the previous parts to this question

# Plotting the log-transformed data 
ggplot(data = cuietal_clean, aes(x= log_genome_length, y = log_virion_volume)) +
    geom_smooth(method = "lm", se = TRUE) +
    theme_bw()+
    labs(x = "log [Genome length (kb)]", y = "log [Virion volume (nm3)]") +
    geom_point()
```
![Reproduced figure](reproducedfigure.png)


**Bonus (10 points) Explain the difference between reproducibility and replicability in scientific research. How can git and GitHub be used to enhance the reproducibility and replicability of your work? What limitations do they have? (e.g. check the platform protocols.io).**

A study is said to be reproducible when its data can be reanalysed using the same metholody, and leads to the same results. Reproducibility therefore does not show whether results are correct, as no new data is collected. It does however allow results to be transparent, as anyone with the data can run the analysis themselves to produce the same results. 
  In contrast, a study is replicable when the whole process of collecting and analysing data is repeated, leading to new data, but the same results. This process tests how robust the findings are when tested under slightly different conditions, and therefore can validate or invalidate the original results by exploring whether they hold true under altered circumstances. 
  Both  high reproducibility and replicability are critical for the credibility and reliability of scientific research, as they give greater support to the validity of the study's conclusions. 

Git is a widely used version control system, as it allows users to track their changes to files and to collaborate with many other users, and GitHub is a hosting service for Git repositories. Both are important platforms to use for producing reproducible and replicable pieces of work. One of the key roles of git is version control: the ability to store different versions of one's work. Git tracks changes in files, and keeps a detailed record of all changes made. This makes the code transparent, as others can see how it was created, and reproducible, as other can then re-run the analyses. Furthermore, the ability to create forks in git allows researchers to experiment with different versions of a project without commiting any changes to the main project. This increases the replicability of the work, as it allows others to see all of the different variations of the project. 
  GitHub is a key platform for hosting the git repositories, where it acts as a central hub for all work. This allows various project files, including code, datasets, and different documentation to be stored in one place. GitHub also allows research to be shared and collaborated on, as by hosting others on a project, they are able to not only view the work as it is being completed, but even contribute. 
  
